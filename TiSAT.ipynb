{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20da39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the detailed code of function predict\n",
    "\n",
    "def predict(exp, setting, load=False):\n",
    "    pred_data, pred_loader = exp._get_data(flag='test')\n",
    "        \n",
    "    if load:\n",
    "        path = os.path.join(exp.args.checkpoints, setting)\n",
    "        best_model_path = path+'/'+'checkpoint.pth'\n",
    "        exp.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    exp.model.eval()\n",
    "        \n",
    "    preds = []\n",
    "        \n",
    "    for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
    "        batch_x = batch_x.float().to(exp.device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "        # decoder input\n",
    "        if exp.args.padding==0:\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        elif exp.args.padding==1:\n",
    "            dec_inp = torch.ones([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        else:\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        dec_inp = torch.cat([batch_y[:,:exp.args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n",
    "        # encoder - decoder\n",
    "        if exp.args.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if exp.args.output_attention:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        else:\n",
    "            if exp.args.output_attention:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        f_dim = -1 if exp.args.features=='MS' else 0\n",
    "        batch_y = batch_y[:,-exp.args.pred_len:,f_dim:].to(exp.device)\n",
    "        \n",
    "        pred = outputs.detach().cpu().numpy()#.squeeze()\n",
    "        \n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    \n",
    "    # result save\n",
    "    folder_path = './results/' + setting +'/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    np.save(folder_path+'real_prediction.npy', preds)\n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4537f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.data = 'custom' # data\n",
    "args.root_path = './Dataset/SWAT/' # root path of data file\n",
    "args.data_path = 'Normal.csv' # data file\n",
    "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'OT' # target feature in S or MS task\n",
    "args.freq = 's' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './checkpoints' # location of model checkpoints\n",
    "\n",
    "# args.data = 'ETTh1' # data\n",
    "# args.root_path = './ETDataset/ETT-small/' # root path of data file\n",
    "# args.data_path = 'ETTh1.csv' # data file\n",
    "# args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "# args.target = 'OT' # target feature in S or MS task\n",
    "# args.freq = 's' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "# args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 100 # input sequence length of Informer encoder\n",
    "args.label_len = 50 # start token length of Informer decoder\n",
    "args.pred_len = 1 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 7 # encoder input size\n",
    "args.dec_in = 7 # decoder input size\n",
    "args.c_out = 7 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "args.freq = 's'\n",
    "\n",
    "args.batch_size = 128\n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 1\n",
    "args.patience = 3\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65371e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8280c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79201b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parser = {\n",
    "    'custom':{'data':'Normal.csv','T':'FIT101','M':[37,37,37]},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d430c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301ad4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp = Exp_Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf801fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "    \n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "    \n",
    "#     # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbf55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.load('./results/'+setting+'/pred.npy')\n",
    "\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e88d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Exp(args)\n",
    "setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n",
    "prediction = predict(exp, setting, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a97099",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load('./results/'+setting+'/pred.npy')\n",
    "trues = np.load('./results/'+setting+'/true.npy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89931f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06726589",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7cb41",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e66b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load('./results/'+setting+'/pred.npy')\n",
    "trues = np.load('./results/'+setting+'/true.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67590a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "det = np.mean((preds[:,0,:]-trues[:,0,:])**2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e140c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(det),100):\n",
    "#     if np.mean(det[i:i+100]) < 1:\n",
    "#         det[i:i+100] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bf1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.read_csv('./Attack.csv',skiprows=1)\n",
    "labels = np.load('labels.npy')\n",
    "GT2 = df_a.loc[df_a['Normal/Attack'] == 'Attack'].index\n",
    "GT2 = [GT2.values][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_stat(score, d_alpha):\n",
    "    stat = np.zeros((1, len(score)+1))\n",
    "    for idx in range(len(score)):\n",
    "        stat[0, idx+1] = np.max((0, stat[0, idx]+score[idx]-d_alpha))\n",
    "    \n",
    "    return stat\n",
    "        \n",
    "accumulated_score = score_to_stat(det, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed62cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accumulated_score[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [[0,1756],[1757,2696],[2697,3070],[3071,3513],[3514,4922],[4923,5305],[5306,6461],[6462,6851],[6852,7257],[7258,7453],[7454,7707],[7708,8136],[8137,11412],[11413,12376],[12377,15382],[15383,16103],[16104,73802],[73803,74523],[74524,90687],[90688,90920],[90921,92142],[92143,92573],[92574,93447],[93448,93723],[93724,103094],[103095,103811],[103812,115845],[115846,116104],[116105,116145],[116146,116540],[116541,117002],[117003,117723],[117724,132920],[132921,133383],[133384,142956],[142957,143653],[143654,172270],[172271,172591],[172592,172912],[172913,173524],[173525,198298],[198299,199743],[199744,227830],[227831,263730],[263731,279122],[279123,279243],[279244,280062],[280063,281233],[281234,302655],[302656,303022],[303023,347681],[347682,348282],[348283,361193],[361194,361637],[361638,371481],[371482,371582],[371583,371857],[371858,372338],[372339,389682],[389683,390222],[390223,436543],[436544,437012],[437013,437419],[437420,437700],[437701,438149],[438150,438550],[438551,438623],[438624,438920],[438621,443503],[443504,445193],[445194,449921]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_f = list()\n",
    "precision_f = list()\n",
    "max_delay = 5000\n",
    "max_window = 5000\n",
    "\n",
    "for thr in range(0,20000,100):\n",
    "    add = list()\n",
    "    precision = list()\n",
    "    tp = list()\n",
    "    fp = list()\n",
    "    for event in range(0,len(ranges)-1,2):\n",
    "\n",
    "        stat = accumulated_score[0,ranges[event][0]:ranges[event+1][1]]\n",
    "        anomaly_stat = accumulated_score[0,ranges[event+1][0]:ranges[event+1][1]]\n",
    "        \n",
    "        alarm = np.where(np.array(stat) >= thr)[0] + ranges[event][0]\n",
    "        \n",
    "        if len(alarm) and np.max(alarm) >= ranges[event+1][0] > 0:\n",
    "            if alarm[0] < ranges[event][1]:\n",
    "                fpc = 0\n",
    "                for ev in range(0,ranges[event][1]-max_window-ranges[event][0],max_window):\n",
    "                    if len(np.where(np.array(stat)[ev:ev+max_window] >= thr)[0]) > 0:\n",
    "                        fpc+=1\n",
    "                fp.append(fpc)\n",
    "                tp.append(1) if np.max(alarm) >= ranges[event+1][0] else tp.append(0)\n",
    "                add.append(np.where(np.array(anomaly_stat) >= thr)[0][0])\n",
    "#                 precision.append(tp[0]/(tp[0]+fpc))\n",
    "            else:\n",
    "#                 print(alarm[0],thr)\n",
    "                delay = alarm[0]-ranges[event][1]\n",
    "                if delay < max_delay:\n",
    "                    add.append(delay)\n",
    "                    precision.append(1)\n",
    "                    tp.append(1)\n",
    "                    fp.append(0)\n",
    "                else:\n",
    "                    add.append(max_delay)\n",
    "                    precision.append(0)\n",
    "                    tp.append(0)\n",
    "                    fp.append(1)\n",
    "                \n",
    "        else:\n",
    "            add.append(max_delay)\n",
    "            fp.append(0)\n",
    "            tp.append(0)\n",
    "            \n",
    "    if np.mean(tp) + np.mean(fp) != 0:\n",
    "        add_f.append(np.mean(add))\n",
    "        precision_f.append(np.sum(tp)/(np.sum(tp)+np.sum(fp)))\n",
    "#         precision_f.append(np.mean(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926bcf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.auc(np.array(add_f)/max_delay, precision_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06123b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 50\n",
    "df_n = pd.read_csv('Normal.csv',skiprows=1)\n",
    "df_a = pd.read_csv('Attack.csv',skiprows=1)\n",
    "\n",
    "Alarms2 = (np.where(accumulated_score[0,:] >= thr))[0] \n",
    "N_Alarms2 = (np.where(accumulated_score[0,:] < thr))[0]\n",
    "\n",
    "GT2 = df_a.loc[df_a['Normal/Attack'] == 'Attack'].index\n",
    "GT2 = [GT2.values][0]\n",
    "\n",
    "NT2 = df_a.loc[df_a['Normal/Attack'] == 'Normal'].index\n",
    "NT2 = [NT2.values][0]\n",
    "\n",
    "\n",
    "TP2 = list(set(Alarms2.tolist()) & set((GT2.tolist())))\n",
    "TN2 = list(set(N_Alarms2.tolist()) & set((NT2.tolist())))\n",
    "FP2 = list(set(Alarms2.tolist()) & set((NT2.tolist())))\n",
    "FN2 = list(set(N_Alarms2.tolist()) & set((GT2.tolist())))\n",
    "\n",
    "PRE2 = len(TP2)/(len(TP2)+len(FP2))\n",
    "REC2 = len(TP2)/(len(TP2)+len(FN2))\n",
    "F12 = 2*PRE2*REC2/(PRE2+REC2)\n",
    "\n",
    "print(PRE2,REC2,F12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098679b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a1362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
